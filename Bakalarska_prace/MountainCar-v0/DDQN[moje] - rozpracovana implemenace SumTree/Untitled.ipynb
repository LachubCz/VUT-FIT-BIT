{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770.0\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770.0\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 11.0   memory length: 12   epsilon: 0.988065780494209\n",
      "episode: 1   score: 13.0   memory length: 26   epsilon: 0.9743224148844496\n",
      "episode: 2   score: 26.0   memory length: 53   epsilon: 0.9483548639781193\n",
      "episode: 3   score: 11.0   memory length: 65   epsilon: 0.9370369888620198\n",
      "episode: 4   score: 22.0   memory length: 88   epsilon: 0.9157205572498949\n",
      "episode: 5   score: 11.0   memory length: 100   epsilon: 0.9047921471137096\n",
      "episode: 6   score: 23.0   memory length: 124   epsilon: 0.8833250364922639\n",
      "episode: 7   score: 37.0   memory length: 162   epsilon: 0.8503722756378911\n",
      "episode: 8   score: 24.0   memory length: 187   epsilon: 0.8293661352855802\n",
      "episode: 9   score: 26.0   memory length: 214   epsilon: 0.8072619457390746\n",
      "episode: 10   score: 9.0   memory length: 224   epsilon: 0.7992255563671304\n",
      "episode: 11   score: 19.0   memory length: 244   epsilon: 0.7833919908382508\n",
      "episode: 12   score: 24.0   memory length: 269   epsilon: 0.7640404167313927\n",
      "episode: 13   score: 52.0   memory length: 322   epsilon: 0.724581445483085\n",
      "episode: 14   score: 9.0   memory length: 332   epsilon: 0.7173681503955072\n",
      "episode: 15   score: 32.0   memory length: 365   epsilon: 0.6940698870404746\n",
      "episode: 16   score: 9.0   memory length: 375   epsilon: 0.6871603381721801\n",
      "episode: 17   score: 14.0   memory length: 390   epsilon: 0.6769247732130653\n",
      "episode: 18   score: 15.0   memory length: 406   epsilon: 0.6661748299656206\n",
      "episode: 19   score: 12.0   memory length: 419   epsilon: 0.6575663287622622\n",
      "episode: 20   score: 11.0   memory length: 431   epsilon: 0.6497187878551962\n",
      "episode: 21   score: 10.0   memory length: 442   epsilon: 0.6426075087326283\n",
      "episode: 22   score: 12.0   memory length: 455   epsilon: 0.6343035511776761\n",
      "episode: 23   score: 9.0   memory length: 465   epsilon: 0.6279889833423202\n",
      "episode: 24   score: 23.0   memory length: 489   epsilon: 0.6130893082982078\n",
      "episode: 25   score: 14.0   memory length: 504   epsilon: 0.6039570649304998\n",
      "episode: 26   score: 15.0   memory length: 520   epsilon: 0.5943658896200158\n",
      "episode: 27   score: 12.0   memory length: 533   epsilon: 0.5866853240299091\n",
      "episode: 28   score: 16.0   memory length: 550   epsilon: 0.5767910651721362\n",
      "episode: 29   score: 15.0   memory length: 566   epsilon: 0.5676313011014509\n",
      "episode: 30   score: 14.0   memory length: 581   epsilon: 0.5591761753724176\n",
      "episode: 31   score: 8.0   memory length: 590   epsilon: 0.5541636732359665\n",
      "episode: 32   score: 9.0   memory length: 600   epsilon: 0.5486469074854965\n",
      "episode: 33   score: 23.0   memory length: 624   epsilon: 0.5356297035976458\n",
      "episode: 34   score: 10.0   memory length: 635   epsilon: 0.5297671482893791\n",
      "episode: 35   score: 12.0   memory length: 648   epsilon: 0.522921346063882\n",
      "episode: 36   score: 15.0   memory length: 664   epsilon: 0.5146170632018707\n",
      "episode: 37   score: 11.0   memory length: 676   epsilon: 0.508475510208194\n",
      "episode: 38   score: 25.0   memory length: 702   epsilon: 0.49541908701565013\n",
      "episode: 39   score: 13.0   memory length: 716   epsilon: 0.4885281230967259\n",
      "episode: 40   score: 13.0   memory length: 730   epsilon: 0.48173300809637676\n",
      "episode: 41   score: 28.0   memory length: 759   epsilon: 0.46795658559511777\n",
      "episode: 42   score: 8.0   memory length: 768   epsilon: 0.4637617835123936\n",
      "episode: 43   score: 10.0   memory length: 779   epsilon: 0.4586858344239834\n",
      "episode: 44   score: 9.0   memory length: 789   epsilon: 0.4541195619962011\n",
      "episode: 45   score: 14.0   memory length: 804   epsilon: 0.44735524511437874\n",
      "episode: 46   score: 14.0   memory length: 819   epsilon: 0.4406916858010624\n",
      "episode: 47   score: 19.0   memory length: 839   epsilon: 0.4319610832451573\n",
      "episode: 48   score: 10.0   memory length: 850   epsilon: 0.427233198057808\n",
      "episode: 49   score: 14.0   memory length: 865   epsilon: 0.42086936576352424\n",
      "episode: 50   score: 8.0   memory length: 874   epsilon: 0.41709665746876984\n",
      "episode: 51   score: 12.0   memory length: 887   epsilon: 0.41170681546900234\n",
      "episode: 52   score: 15.0   memory length: 903   epsilon: 0.40516868143104934\n",
      "episode: 53   score: 8.0   memory length: 912   epsilon: 0.4015367153875324\n",
      "episode: 54   score: 8.0   memory length: 921   epsilon: 0.3979373065922575\n",
      "episode: 55   score: 12.0   memory length: 934   epsilon: 0.39279504719041636\n",
      "episode: 56   score: 14.0   memory length: 949   epsilon: 0.38694418677575626\n",
      "episode: 57   score: 14.0   memory length: 964   epsilon: 0.38118047758114515\n",
      "episode: 58   score: 11.0   memory length: 976   epsilon: 0.3766313860903695\n",
      "episode: 59   score: 12.0   memory length: 989   epsilon: 0.3717644478715407\n",
      "episode: 60   score: 66.0   memory length: 1056   epsilon: 0.34766067307894\n",
      "episode: 61   score: 76.0   memory length: 1133   epsilon: 0.32188308869613635\n",
      "episode: 62   score: 100.0   memory length: 1234   epsilon: 0.2909460536500286\n",
      "episode: 63   score: 58.0   memory length: 1293   epsilon: 0.2742687177907501\n",
      "episode: 64   score: 96.0   memory length: 1390   epsilon: 0.24890214202456656\n",
      "episode: 65   score: 66.0   memory length: 1457   epsilon: 0.23276428588715223\n",
      "episode: 66   score: 37.0   memory length: 1495   epsilon: 0.22408092978220462\n",
      "episode: 67   score: 34.0   memory length: 1530   epsilon: 0.2163699704438582\n",
      "episode: 68   score: 38.0   memory length: 1569   epsilon: 0.20808991201225926\n",
      "episode: 69   score: 35.0   memory length: 1605   epsilon: 0.20072829824190555\n",
      "episode: 70   score: 28.0   memory length: 1634   epsilon: 0.19498794456453009\n",
      "episode: 71   score: 31.0   memory length: 1666   epsilon: 0.18884408419144066\n",
      "episode: 72   score: 29.0   memory length: 1696   epsilon: 0.18326014728381135\n",
      "episode: 73   score: 70.0   memory length: 1767   epsilon: 0.17069377976089034\n",
      "episode: 74   score: 65.0   memory length: 1833   epsilon: 0.15978643901921685\n",
      "episode: 75   score: 46.0   memory length: 1880   epsilon: 0.15244664284569598\n",
      "episode: 76   score: 50.0   memory length: 1931   epsilon: 0.14486309656989407\n",
      "episode: 77   score: 91.0   memory length: 2000   epsilon: 0.1321242944480742\n",
      "episode: 78   score: 66.0   memory length: 2000   epsilon: 0.12355786412844308\n",
      "episode: 79   score: 63.0   memory length: 2000   epsilon: 0.11589418313627514\n",
      "episode: 80   score: 97.0   memory length: 2000   epsilon: 0.10507018209186142\n",
      "episode: 81   score: 116.0   memory length: 2000   epsilon: 0.09346340681465164\n",
      "episode: 82   score: 68.0   memory length: 2000   epsilon: 0.08722887973501425\n",
      "episode: 83   score: 44.0   memory length: 2000   epsilon: 0.08338871185087363\n",
      "episode: 84   score: 42.0   memory length: 2000   epsilon: 0.07987727835923124\n",
      "episode: 85   score: 67.0   memory length: 2000   epsilon: 0.07462364496809594\n",
      "episode: 86   score: 36.0   memory length: 2000   epsilon: 0.0719116945222669\n",
      "episode: 87   score: 60.0   memory length: 2000   epsilon: 0.06765412855912437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 88   score: 118.0   memory length: 2000   epsilon: 0.06006028701082751\n",
      "episode: 89   score: 41.0   memory length: 2000   epsilon: 0.05758878404316422\n",
      "episode: 90   score: 53.0   memory length: 2000   epsilon: 0.054559988854462366\n",
      "episode: 91   score: 66.0   memory length: 2000   epsilon: 0.051022529337921396\n",
      "episode: 92   score: 82.0   memory length: 2000   epsilon: 0.04695669336685328\n",
      "episode: 93   score: 80.0   memory length: 2000   epsilon: 0.043301411481269855\n",
      "episode: 94   score: 62.0   memory length: 2000   epsilon: 0.04065629616391608\n",
      "episode: 95   score: 101.0   memory length: 2000   epsilon: 0.03671196329033828\n",
      "episode: 96   score: 178.0   memory length: 2000   epsilon: 0.030692340165275823\n",
      "episode: 97   score: 155.0   memory length: 2000   epsilon: 0.026257064205012406\n",
      "episode: 98   score: 194.0   memory length: 2000   epsilon: 0.021603114634930247\n",
      "episode: 99   score: 199.0   memory length: 2000   epsilon: 0.01768536450897841\n",
      "episode: 100   score: 199.0   memory length: 2000   epsilon: 0.014478102954178184\n",
      "episode: 101   score: 222.0   memory length: 2000   epsilon: 0.011582852741435093\n",
      "episode: 102   score: 250.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 103   score: 195.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 104   score: 236.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 105   score: 140.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 106   score: 168.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 107   score: 186.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 108   score: 150.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 109   score: 154.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 110   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 111   score: 249.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 112   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 113   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 114   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 115   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 116   score: 419.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 117   score: 308.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 118   score: 398.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 119   score: 384.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 120   score: 451.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 121   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 122   score: 48.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 123   score: 103.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 124   score: 440.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 125   score: 440.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 126   score: 279.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 127   score: 254.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 128   score: 220.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 129   score: 43.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 130   score: 194.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 131   score: 38.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 132   score: 21.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 133   score: 21.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 134   score: 12.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 135   score: 15.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 136   score: 15.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 137   score: 14.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 138   score: 10.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 139   score: 11.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 140   score: 12.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 141   score: 10.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 142   score: 16.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 143   score: 29.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 144   score: 21.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 145   score: 59.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 146   score: 240.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 147   score: 393.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 148   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 149   score: 384.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 150   score: 345.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 151   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 152   score: 311.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 153   score: 411.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 154   score: 426.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 155   score: 304.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 156   score: 392.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 157   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 158   score: 254.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 159   score: 228.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 160   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 161   score: 287.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 162   score: 418.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 163   score: 375.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 164   score: 233.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 165   score: 259.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 166   score: 265.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 167   score: 224.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 168   score: 245.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 169   score: 436.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 170   score: 232.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 171   score: 290.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 172   score: 309.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 173   score: 228.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 174   score: 395.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 175   score: 250.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 176   score: 221.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 177   score: 271.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 178   score: 437.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 179   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 180   score: 351.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 181   score: 267.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 182   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 183   score: 316.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 184   score: 264.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 185   score: 486.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 186   score: 395.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 187   score: 280.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 188   score: 359.0   memory length: 2000   epsilon: 0.009998671593271896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 189   score: 454.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 190   score: 292.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 191   score: 475.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 192   score: 325.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 193   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 194   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 195   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 196   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 197   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 198   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 199   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 200   score: 336.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 201   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 202   score: 381.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 203   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 204   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 205   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 206   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 207   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 208   score: 353.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 209   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 210   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 211   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 212   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 213   score: 494.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 214   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 215   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 216   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 217   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 218   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LachubCz_NTB\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "EPISODES = 300\n",
    "\n",
    "\n",
    "# Double DQN Agent for the Cartpole\n",
    "# it uses Neural Network to approximate q function\n",
    "# and replay memory & target q network\n",
    "class DoubleDQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # if you want to see Cartpole learning, then change to True\n",
    "        self.render = False\n",
    "        self.load_model = False\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # these is hyper parameters for the Double DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        # initialize target model\n",
    "        self.update_target_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./cartpole_ddqn.h5\")\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(24, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # after some time interval update the target model to be same with model\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size)\n",
    "    def train_model(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        update_input = np.zeros((batch_size, self.state_size))\n",
    "        update_target = np.zeros((batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            update_input[i] = mini_batch[i][0]\n",
    "            action.append(mini_batch[i][1])\n",
    "            reward.append(mini_batch[i][2])\n",
    "            update_target[i] = mini_batch[i][3]\n",
    "            done.append(mini_batch[i][4])\n",
    "\n",
    "        target = self.model.predict(update_input)\n",
    "        target_next = self.model.predict(update_target)\n",
    "        target_val = self.target_model.predict(update_target)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # like Q Learning, get maximum Q value at s'\n",
    "            # But from target model\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                # the key point of Double DQN\n",
    "                # selection of action is from model\n",
    "                # update is from target model\n",
    "                a = np.argmax(target_next[i])\n",
    "                target[i][action[i]] = reward[i] + self.discount_factor * (\n",
    "                    target_val[i][a])\n",
    "\n",
    "        # make minibatch which includes target q value and predicted q value\n",
    "        # and do the model fit!\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size,\n",
    "                       epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # In case of CartPole-v1, you can play until 500 time step\n",
    "    env = gym.make('CartPole-v1')\n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = DoubleDQNAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "\n",
    "        while not done:\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "\n",
    "            # get action for the current state and go one step in environment\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            # if an action make the episode end, then gives penalty of -100\n",
    "            reward = reward if not done or score == 499 else -100\n",
    "\n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            # every time step do the training\n",
    "            agent.train_model()\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                # every episode update the target model to be same with model\n",
    "                agent.update_target_model()\n",
    "\n",
    "                # every episode, plot the play time\n",
    "                score = score if score == 500 else score + 100\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./cartpole_ddqn.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "                # if the mean of scores of last 10 episode is bigger than 490\n",
    "                # stop training\n",
    "                if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
    "                    sys.exit()\n",
    "\n",
    "        # save the model\n",
    "        if e % 50 == 0:\n",
    "            agent.model.save_weights(\"./cartpole_ddqn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
