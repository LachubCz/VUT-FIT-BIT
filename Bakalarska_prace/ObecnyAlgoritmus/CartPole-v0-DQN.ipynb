{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a inicializace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import copy                                  # Kopirovani prvku\n",
    "import numpy as np                           # Matematicke operace s maticemi\n",
    "import random                                # Vyber nahodnych prvku\n",
    "import h5py                                  # Ukladani vah site\n",
    "import gym                                   # Prostredi Open AI Gym\n",
    "#from gym import wrappers                    # Nahravani zaznamu\n",
    "environment = \"MountainCar-v0\"               # Jmeno prostredi\n",
    "env = gym.make(environment)                  # Konkretni hra z Open AI Gym\n",
    "#env = wrappers.Monitor(env, '/home/lachubcz/tmp/cartpole-experiment-1', force=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque                # Pamet\n",
    "from __future__ import division              # Deleni realnych cisel (kvuli nizsi verzi Pythonu 2.6)\n",
    "from tqdm import tnrange, tqdm_notebook      # Progress bar\n",
    "from sources.profiling import * #profiling - @do_profile(follow=[method, ])\n",
    "from sources.playing import *\n",
    "from sources.visualization import *\n",
    "from sources.agent import *\n",
    "\n",
    "#Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "#Tensorflow session\n",
    "import tensorflow as tf                     # Knihovna Tensorflow\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Parametry\n",
    "observetime = 200                            # Delka pozorovani\n",
    "episodes = 1                              # Pocet epizod\n",
    "games = 25                                   # Pocet her\n",
    "scores = []                                  # Pole pro ulozeni vysledku na analyzu\n",
    "episodesList = []                            # Pole pro ulozeni cisel epizod na analyzu\n",
    "bestScore = float(\"-inf\")                    # Promenna pro ukladani nejlepsiho prubezneho vysledku\n",
    "best_avg_score = float(\"-inf\")               # Promenna pro ukladani nejlepsiho prumerneho vysledku\n",
    "actionCount = env.action_space.n             # Pocet vstupu do prostredi\n",
    "stateSize = env.observation_space.shape[0]   # Pocet vystupu z prostredi\n",
    "agent = Agent(env)                           # Vytvoreni agenta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rand_agent_replay(env, agent, 10000, 500, actionCount)\n",
    "\n",
    "#agent.loadNN(\"./DDQN-MountainCar-v0.h5\")                                     # Nacteni vah NN\n",
    "#agent.updateTargetNet()                                                      # Nacteni NN do netTarget\n",
    "\n",
    "for eps in tnrange(episodes, desc='episodes'):\n",
    "    state = env.reset()                                                   # Resetovani prostredi\n",
    "    total_reward = 0                                                      # Vynulovani hodnoty za kolo\n",
    "    \n",
    "    for t in range(observetime):\n",
    "        state = np.reshape(state, (1, stateSize))                         # Formatovani\n",
    "        action = agent.getActionWE(state)                                 # Ziskani akce\n",
    "        nextState, reward, done, info = env.step(action)                  # Provedeni akce\n",
    "\n",
    "        agent.remember(state, action, reward, nextState, done)            # Ulozeni stavu do pameti\n",
    "        agent.trainDQN()                                                  # Trenovani pameti\n",
    "        \n",
    "        state = nextState                                                 # Zmena stavu\n",
    "        total_reward = total_reward + reward                              # Pricteni odmeny za aktualni stav\n",
    "        \n",
    "        agent.epsilonActulization()                                       # Aktualizace epsilon\n",
    "        if done:                                                          # Konec epizody\n",
    "            #agent.updateTargetNet()                                      # Aktualizace target site\n",
    "            \n",
    "            if eps % 50 == 0:\n",
    "                avg_score = score_estimate(env, agent, games, stateSize)  # Vypocet aktualniho skore\n",
    "                scores.append(avg_score)                                  # Ulozeni aktualniho skore\n",
    "                episodesList.append(eps)                                  # Ulozeni aktualniho cisla epizody\n",
    "                \n",
    "                print(\"Episode: {}/{}, epsilon: {:.2}, average score: {}\".format(eps, episodes, agent.currentEpsilon, avg_score))\n",
    "                \n",
    "                if avg_score > best_avg_score and eps != 0:\n",
    "                    best_avg_score = avg_score\n",
    "                    agent_replay(env, agent,  10000, 500, stateSize)\n",
    "                \n",
    "                agent.saveNN(\"./saves/{}-{}.h5\" .format(environment, eps))      # Ulozeni site\n",
    "                \n",
    "            if total_reward > bestScore:                                  # Bylo dosazeno nejlepsiho skore\n",
    "                bestScore = total_reward                                  # Nove nejlepsi skore\n",
    "                print(\"Episode: {}/{}, epsilon: {:.2}, new best score: {}\".format(eps, episodes, agent.currentEpsilon, total_reward))\n",
    "            break\n",
    "\n",
    "agent.saveNN(\"./saves/{}-DONE.h5\" .format(environment, eps))                    # Ulozeni site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretace výsledků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scattergrams_graph(scores, episodesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#learning_graph(env, agent, games, stateSize, 1000, 50, \"./CartPole\", \"CartPole-v0-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_graph(env, agent, games, stateSize, 1000, 50, \"./Experiments-1000\", \"MountainCar-v0-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "from sources.environments import *\n",
    "agent  =1\n",
    "#try:\n",
    "env = Environment(\"CartPole-v1\", agent)\n",
    "env.test()\n",
    "#except:\n",
    "#    print(\"shit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
