{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a inicializace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 675\n",
      "Trainable params: 675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 675\n",
      "Trainable params: 675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import copy                                  # Kopirovani prvku\n",
    "import numpy as np                           # Matematicke operace\n",
    "import random                                # Vyber nahodnych prvku\n",
    "#import sys                                   # Pripojeni knihoven (pro servery)\n",
    "#sys.path.append('/home/xbucha02/libraries')  # Pripojeni knihoven (pro servery)\n",
    "import gym                                   # Prostredi Open AI Gym\n",
    "#from gym import wrappers                    # Nahravani zaznamu\n",
    "environment = \"MountainCar-v0\"\n",
    "env = gym.make(environment)                # Konkretni hra z Open AI Gym\n",
    "#env = wrappers.Monitor(env, '/home/lachubcz/tmp/cartpole-experiment-1', force=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque                # Pamet\n",
    "from __future__ import division              # Deleni realnych cisel (kvuli nizsi verzi Pythonu 2.6)\n",
    "from tqdm import tnrange, tqdm_notebook      # Progress bar\n",
    "from profiling import * #profiling - @do_profile(follow=[method, ])\n",
    "from playing import *\n",
    "from visualization import *\n",
    "from agent import *\n",
    "\n",
    "#Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "#Tensorflow session\n",
    "gpuMemoryUsage=0.5                          # Vyuziti pameti GPU\n",
    "import tensorflow as tf                     # Knihovna Tensorflow\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = gpuMemoryUsage\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Parametry\n",
    "observetime = 200                            # Delka pozorovani\n",
    "episodes = 400                               # Pocet epizod\n",
    "games = 25                                   # Pocet her\n",
    "scores = []                                  # Pole pro ulozeni vysledku na analyzu\n",
    "episodesList = []                            # Pole pro ulozeni cisel epizod na analyzu\n",
    "bestScore = float(\"-inf\")                    # Promenna pro ukladani nejlepsiho prubezneho vysledku\n",
    "best_avg_score = float(\"-inf\")               # Promenna pro ukladani nejlepsiho prumerneho vysledku\n",
    "actionCount = env.action_space.n             # Pocet vstupu do prostredi\n",
    "stateSize = env.observation_space.shape[0]   # Pocet vystupu z prostredi\n",
    "agent = Agent(env)                           # Vytvoreni agenta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ae203262e14ad8bebcf1b4c4738174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0/400, epsilon: 1.0, average score: -200.0\n",
      "Episode: 0/400, epsilon: 1.0, new best score: -200.0\n",
      "Episode: 50/400, epsilon: 0.8, average score: -200.0\n",
      "Episode: 100/400, epsilon: 0.6, average score: -200.0\n",
      "Episode: 150/400, epsilon: 0.4, average score: -200.0\n",
      "Episode: 200/400, epsilon: 0.2, average score: -200.0\n"
     ]
    }
   ],
   "source": [
    "rand_agent_replay(env, agent, 10000, 500, actionCount)\n",
    "\n",
    "#agent.loadNN(\"./DDQN-MountainCar-v0.h5\")                                     # Nacteni vah NN\n",
    "#agent.updateTargetNet()                                                      # Nacteni NN do netTarget\n",
    "\n",
    "for eps in tnrange(episodes, desc='episodes'):\n",
    "    state = env.reset()                                                   # Resetovani prostredi\n",
    "    total_reward = 0                                                      # Vynulovani hodnoty za kolo\n",
    "    \n",
    "    for t in range(observetime):\n",
    "        state = np.reshape(state, (1, stateSize))                         # Formatovani\n",
    "        action = agent.getActionWE(state)                                 # Ziskani akce\n",
    "        nextState, reward, done, info = env.step(action)                  # Provedeni akce\n",
    "\n",
    "        agent.remember(state, action, reward, nextState, done)            # Ulozeni stavu do pameti\n",
    "        agent.trainDQN()                                                  # Trenovani pameti\n",
    "        \n",
    "        state = nextState                                                 # Zmena stavu\n",
    "        total_reward = total_reward + reward                              # Pricteni odmeny za aktualni stav\n",
    "        \n",
    "        agent.epsilonActulization()                                       # Aktualizace epsilon\n",
    "        if done:                                                          # Konec epizody\n",
    "            #agent.updateTargetNet()                                      # Aktualizace target site\n",
    "            \n",
    "            if eps % 50 == 0:\n",
    "                avg_score = score_estimate(env, agent, games, stateSize)  # Vypocet aktualniho skore\n",
    "                scores.append(avg_score)                                  # Ulozeni aktualniho skore\n",
    "                episodesList.append(eps)                                  # Ulozeni aktualniho cisla epizody\n",
    "                \n",
    "                print(\"Episode: {}/{}, epsilon: {:.2}, average score: {}\".format(eps, episodes, agent.currentEpsilon, avg_score))\n",
    "                \n",
    "                if avg_score > best_avg_score and eps != 0:\n",
    "                    best_avg_score = avg_score\n",
    "                    agent_replay(env, agent,  10000, 500, stateSize)\n",
    "                \n",
    "                agent.saveNN(\"./{}-{}.h5\" .format(environment, eps))      # Ulozeni site\n",
    "                \n",
    "            if total_reward > bestScore:                                  # Bylo dosazeno nejlepsiho skore\n",
    "                bestScore = total_reward                                  # Nove nejlepsi skore\n",
    "                print(\"Episode: {}/{}, epsilon: {:.2}, new best score: {}\".format(eps, episodes, agent.currentEpsilon, total_reward))\n",
    "            break\n",
    "\n",
    "agent.saveNN(\"./{}-DONE.h5\" .format(environment, eps))                    # Ulozeni site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretace výsledků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis(scores, episodesList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
